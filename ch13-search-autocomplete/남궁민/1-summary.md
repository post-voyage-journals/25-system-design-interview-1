## 설계 요구사항

- 사용자 입력 단어는 자동완성 검색어들의 첫 부분일 것
- 5개의 자동완성 검색어 제공
  - 검색어 인기순위 기준으로
- 모든 검색은 영어 소문자로 가정
  - 평균 4개 단어로 가정
  - 각 단어는 5글자로 가정
  - 따라서 질의당 평균 20Byte
- DAU 10million (천만 명)
  - 평균적으로 한 명이 매일 10건의 검색을 수행한다고 가정
  - QPS 24,000 ~ 48,000
- 응답속도 100ms 이내
- 질의 가운데 20%는 신규 검색어라고 가정
  - 매일 대략 0.4GB의 신규 데이터 추가

## 설계 및 구현

### 클라이언트의 상호작용

- 검색창에 한 글자를 입력할 때마다 백엔드에 요청 전송
- 따라서 평균적으로 1회 검색당 20건의 요청 전송

### 데이터 수집 서비스

- 사용자가 입력한 질의를 실시간으로 수집하는 시스템
- 검색 단어가 입력될 때마다 `frequency` 테이블에 질의에 대한 검색 빈도 업데이트
  - `query`와 `frequency` 필드로 구분

### 질의 서비스

- 주어진 질의에 5개 인기 검색어를 정렬해서 제공하는 서비스

### 기본적인 SQL 활용 방식

```sql
SELECT * FROM frequency
WHERE query like `prefix%`
ORDER BY frequency DESC
LIMIT 5
```

- 데이터 양이 적을 때는 나쁘지 않지만 데이터가 많아지면 DB 병목이 심해지는 방식

### Trie 자료구조

Trie에 대한 개략적인 설명

- 트리 형태의 자료구조
- 루트 노드는 빈 문자열
- 각 노드는 character 하나씩 추가하면서 저장됨
  - 영어 소문자만 하기로 했으니 26개의 자식 노드를 가질 수 있음
- 각 트리의 노드는 하나의 단어, 혹은 prefix 문자열을 나타냄

시간 복잡도

- prefix 노드를 찾는 작업 O(p)
- prefix 노드부터 시작하는 유효 노드 탐색 O(c)
- 검색어에 대한 자식 노드 개수가 n일 때 질의 시간 O(clogc)
- 최악의 경우에는 전체 트라이를 다 검색해야 할 수도 있음

최적화 방안 1: prefix 최대 길이 제한

- 사용자가 긴 검색어를 입력하는 일이 거의 없음
- 50글자 정도로 제한한다면 prefix 노드를 찾는 작업을 O(p)에서 O(1)으로 절감

최적화 방안 2: 노드에 인기 검색어 캐시

- 인기 검색어에 해당하는 노드에 미리 5개의 자동완성 검색어 캐싱
- 질의 시간 O(clogc)에서 O(1)으로 절

### 데이터 수집 서비스 개선

- 매일 수천만 건의 질의마다 트라이 갱신은 비효율적
- 사실 트라이가 한번 구축되면 인기 검색어는 그다지 자주 바뀌지 않음
  - 다만 실시간성을 얼마나 중요하게 여기느냐에 따라 달라질 수는 있음
- 따라서 로그를 적재해두고 일주일에 한 번 정도 취합하면 효율화 가능

구성 방식

- worker
  - 주기적으로 비동기적인 cron job 수행
  - 트라이 자료구조를 만들고 검색어 저장
- 트라이 캐시
  - 분산 캐시 시스템
  - 트라이 데이터를 메모리에 유지해서 읽기 성능 향상
- 트라이 데이터베이스
  - MongoDB 같은 문서형 혹은 key-value 저장소 활용

### 질의 서비스 개선 방안

구성 방식

- 로드밸런서
- API 서버는 트라이 캐시를 먼저 조회하고, 없으면 DB 조회

최적화 방안들

- AJAX 요청
  - 요청에 대한 응답을 받기 위해 페이지 새로고침을 할 필요가 없게 됨
- 브라우저 캐싱
  - 검색어 제안 결과는 보통 짧은 시간 내에 바뀌지 않음
  - `cache-control` 헤더를 활용해 1시간 정도 캐시
- 데이터 샘플링
  - 모든 요청을 로깅하면 자원 소모가 심하므로 N개의 요청 중 1개의 요청만 로깅하도록 변경

### 트라이 검색어 삭제

- 혐오성, 폭력성, 성적인 질의어는 자동완성 결과에서 제거해야 함
- 트라이 캐시 앞에 필터 계층을 둠으로써 부적절한 질의어가 반환되지 않도록 처리
- 검색어 물리적 삭제는 트라이 비동기적 업데이트 사이클 때 처리

### 저장소 샤딩 전략

- 영어 소문자만 지원하면 되므로, 첫 글자를 기준으로 26개 문자를 서버 대수 만큼 나눠서 보관하는 방식
  - 26대 이상으로 서버를 늘리고자 한다면 계층적 샤딩 필요
    - 두번째 글자부터 다시 계층적으로 샤딩하는 방식
  - 하지만 'c'로 시작하는 단어가 'x'로 시작하는 단어보다 훨씬 많듯이, 균등한 분산이 안됨
- 과거 질의 패턴을 분석해서 샤딩하는 방식 추천
  - 영어 소문자 기반으로 데이터들을 나누되, 검색어 수가 적은 것들끼리 같은 샤드에 배치하는 방식

## 추가 고려사항들

- 다국어 지원 방법
  - ASCII 대신 유니코드를 저장하는 방식으로 변경
- 국가별로 인기 검색어 순위가 다르다면?
  - 국가별로 다른 트라이를 사용
  - 트라이를 CDN에 저장해서 응답속도를 높일 수 있을 것
- 실시간성을 보장하는 방법
  - 샤딩을 통해 작업 대상 데이터 양 절감
  - 랭킹 모델을 바꿔서 최근 검색어에 더 높은 가중치 부여
  - Kafka 등의 데이터 스트림 활용
