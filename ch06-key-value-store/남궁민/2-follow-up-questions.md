# 면접 꼬리 질문 (5장 + 6장)

<details>
<summary>Q1. 안정 해시(consistent hashing)를 사용했을 때의 문제점은 없을까요?</summary>

1. **불균등한 데이터 분산**: 노드가 적거나 해시 함수의 분포가 고르지 않으면 특정 노드에 데이터가 집중될 수 있습니다.

2. **핫스팟 문제**: 특정 키에 대한 접근이 집중되면 해당 키를 담당하는 노드에 과부하가 발생합니다.

3. **가상 노드 오버헤드**: 균등한 분산을 위해 가상 노드를 사용하면 메타데이터 관리 비용이 증가하고, 라우팅 테이블이 커집니다.

4. **복제본 배치의 복잡성**: 동일한 물리 서버에 복제본이 배치되지 않도록 하는 추가 로직이 필요합니다.

5. **노드 추가/제거 시 일시적 불일치**: 데이터 재분배 과정에서 일부 요청이 잘못된 노드로 라우팅될 수 있습니다.

해결 방법으로는 가상 노드 활용, 모니터링 기반 동적 재분배, 점진적 데이터 마이그레이션 등이 있습니다.
</details>

<details>
<summary>Q2. 안정 해시 링에서 특정 노드에 장애가 발생했을 때, 데이터 재분배 과정 중의 일시적 불일치를 어떻게 해결할까요?</summary>

1. **Hinted Handoff**:
   - 장애 노드의 데이터를 임시로 다음 노드가 보관
   - 장애 노드 복구 시 힌트 기반으로 데이터를 원래 노드로 반환
   - 일시적 장애에 효과적

2. **읽기 복구(Read Repair)**:
   - 읽기 요청 시 여러 복제본의 데이터를 비교
   - 불일치 발견 시 최신 버전으로 자동 업데이트
   - 자주 읽히는 데이터의 일관성 유지에 효과적

3. **Anti-Entropy Protocol**:
   - Merkle Tree를 사용한 주기적인 복제본 비교
   - 차이가 발견되면 동기화 수행
   - 백그라운드에서 지속적으로 일관성 보장

4. **버전 벡터/벡터 시계**:
   - 각 데이터의 버전을 추적
   - 충돌 발생 시 클라이언트 또는 애플리케이션에서 해결

5. **점진적 마이그레이션**:
   - 데이터를 한 번에 이동하지 않고 점진적으로 재분배
   - 이중 읽기/쓰기로 전환 과정에서도 서비스 유지
</details>

<details>
<summary>Q3. 분산형 키-밸류 저장소를 구현한다고 했을 때, 데이터 일관성을 100% 보장하기 위해서는 어떻게 해야 할까요?</summary>

강한 일관성(Strong Consistency)을 보장하기 위한 방법:

1. **합의 프로토콜 사용**:
   - Paxos, Raft 같은 합의 알고리즘 적용
   - 과반수 이상의 노드가 동의해야 쓰기 완료
   - 리더 선출을 통한 순차적 쓰기 보장

2. **2PC(Two-Phase Commit)**:
   - Prepare 단계: 모든 참여자에게 쓰기 준비 요청
   - Commit 단계: 모든 참여자가 준비되면 커밋 수행
   - 하나라도 실패하면 전체 롤백

3. **정족수 설정 강화**:
   - R + W > N이 아닌 R = W = N으로 설정
   - 모든 복제본을 읽고 쓰기 때문에 강한 일관성 보장
   - 단, 가용성과 성능이 크게 저하됨

4. **단일 마스터 아키텍처**:
   - 모든 쓰기를 단일 마스터 노드에서 처리
   - 순차적 일관성 보장
   - 마스터가 SPOF(Single Point of Failure)가 될 위험

**트레이드오프**: CAP 정리에 따라 일관성을 100% 보장하면 가용성과 파티션 허용성이 저하됩니다. 실무에서는 비즈니스 요구사항에 따라 적절한 균형점을 찾는 것이 중요합니다.
</details>

<details>
<summary>Q4. 분산형 키-밸류 저장소를 구현한다고 했을 때, 가용성을 100%에 가깝도록 보장하기 위해서는 어떻게 해야 할까요?</summary>

고가용성을 달성하기 위한 방법:

1. **다중 복제(Multi-Replication)**:
   - N값을 충분히 크게 설정 (예: N=5 이상)
   - 지리적으로 분산된 데이터센터에 복제본 배치
   - 하나 이상의 장애를 견딜 수 있도록 설계

2. **느슨한 정족수(Sloppy Quorum)**:
   - 정확히 지정된 N개 노드가 아닌, 가용한 N개 노드 중 W/R개만 충족하면 성공
   - Hinted Handoff와 함께 사용
   - 일시적 장애 시에도 서비스 지속

3. **Gossip 프로토콜 기반 장애 감지**:
   - 빠른 장애 감지와 자동 복구
   - 중앙 코디네이터 없이 분산 방식으로 상태 공유
   - 단일 장애점 제거

4. **자동 페일오버**:
   - 장애 노드 감지 시 자동으로 복제본 승격
   - 로드 밸런서의 자동 재라우팅
   - 최소한의 다운타임으로 복구

5. **멀티 리전 배포**:
   - 리전 단위 장애에도 대응 가능
   - 각 리전에 독립적인 복제본 세트 유지
   - 크로스 리전 복제로 데이터 동기화

6. **백프레셔와 서킷 브레이커**:
   - 과부하 시 요청 제한으로 시스템 보호
   - 장애 전파 방지

**트레이드오프**: 높은 가용성을 위해 결과적 일관성을 허용해야 하며, 인프라 비용이 증가합니다.
</details>

<details>
<summary>Q5. 안정 해시에서 가상 노드 방식을 사용하고 데이터 다중화(replication)를 추가해야 한다면, 어떻게 동일한 물리 서버에 동일한 키가 들어가지 않게 할 수 있을까요?</summary>

1. **복제본 배치 알고리즘**:
   - 키의 복제본을 저장할 때, 링을 시계방향으로 순회하면서 다음 N개의 **서로 다른 물리 서버**를 선택
   - 각 가상 노드가 어떤 물리 서버에 속하는지 메타데이터로 관리
   - 예: `virtual_node -> physical_server` 매핑 테이블

2. **Rack-Aware/Zone-Aware 배치**:
   - 물리 서버뿐만 아니라 랙(Rack)이나 가용 영역(AZ) 정보도 고려
   - 동일한 장애 도메인에 복제본이 모이지 않도록 배치
   - 데이터센터 레벨의 장애에도 대응 가능

3. **일관성 검증**:
   - 주기적으로 복제본 배치를 검증
   - 동일 물리 서버에 중복 발견 시 자동 재배치
</details>

<details>
<summary>Q6. 결과적 일관성을 보장하기 위한 방법 중, 버저닝과 벡터 시계 방식의 차이점을 설명해주세요.</summary>

**버저닝(Versioning)**:
- **개념**: 데이터의 각 변경마다 단순히 버전 번호를 증가시키는 방식
- **구조**: 단일 카운터 (예: v1, v2, v3...)
- **충돌 감지**: 동일 버전에서 분기된 쓰기가 발생하면 충돌 감지 어려움
- **한계**: 분산 환경에서 여러 노드가 동시에 쓰기를 수행할 때 인과관계 파악 불가능
- **사용 예**: 단일 서버 환경, 마스터-슬레이브 복제

**벡터 시계(Vector Clock)**:
- **개념**: 각 노드별로 독립적인 카운터를 유지하는 방식
- **구조**: `[(node1, counter1), (node2, counter2), ...]`
- **충돌 감지**:
  - 벡터 A가 B를 포함하면 A가 최신 (인과관계 명확)
  - 서로 포함하지 않으면 충돌 발생 (동시 쓰기)
- **장점**:
  - 분산 환경에서 인과관계 정확히 추적
  - 동시 발생(concurrent) 쓰기를 정확히 감지
- **단점**:
  - 벡터 크기가 노드 수에 비례해 증가
  - 클라이언트가 벡터 시계를 포함한 메타데이터 전달 필요
- **사용 예**: DynamoDB, Riak, Cassandra
</details>

<details>
<summary>Q7. 정족수(Quorum) 기반 읽기/쓰기에서 R + W > N 조건을 만족하지 않으면 어떤 문제가 발생할까요?</summary>

**R + W > N 조건의 의미**:
- 읽기와 쓰기가 최소 하나의 노드에서 겹치도록 보장
- 이를 통해 읽기 시 최신 데이터를 볼 수 있음을 보장

**조건을 만족하지 않을 때의 문제**:

1. **Stale Read (오래된 데이터 읽기)**:
   - 예: N=3, W=1, R=1 (R+W=2 ≤ N)
   - 노드 A에만 쓰고, 노드 C에서만 읽으면 업데이트 전 데이터 반환
   - 읽기와 쓰기 노드가 겹치지 않을 수 있음

2. **쓰기 손실(Write Loss)**:
   - 동시 쓰기 시 서로 다른 노드 집합에 기록
   - 나중에 동기화 시 한쪽 쓰기가 덮어써질 수 있음

3. **일관성 보장 불가**:
   - 읽기 시 여러 버전의 데이터 중 어느 것이 최신인지 확신할 수 없음
   - 애플리케이션이 직접 충돌 해결 필요

**적절한 설정 예시**:
- 강한 일관성: R=W=N/2+1 (예: N=3, R=2, W=2)
- 쓰기 최적화: R=N, W=1 (모든 노드에서 읽지만 하나만 쓰기)
- 읽기 최적화: R=1, W=N (하나만 읽지만 모든 노드에 쓰기)

**조건을 만족하지 않으면 가용성은 높아지지만, 결과적 일관성도 보장할 수 없게 됩니다.**
</details>

<details>
<summary>Q8. 분산 키-밸류 저장소에서 핫 파티션 문제를 어떻게 감지하고 해결할 수 있을까요?</summary>

**감지 방법**:

1. **메트릭 모니터링**:
   - CPU, 메모리, 네트워크 I/O, 디스크 I/O를 노드별로 추적
   - 특정 노드의 부하가 평균 대비 2배 이상이면 핫 파티션 의심
   - 요청 수, 처리 지연시간(latency) 모니터링

2. **키별 접근 패턴 분석**:
   - 각 키의 읽기/쓰기 빈도 추적
   - 상위 1%의 키가 전체 트래픽의 과도한 비율 차지 시 핫키 감지
   - Bloom filter나 Count-Min Sketch 같은 확률적 자료구조 활용

3. **분산 추적(Distributed Tracing)**:
   - 요청 경로를 추적하여 병목 지점 파악
   - 특정 파티션으로 요청이 집중되는지 확인

**해결 방법**:

1. **핫키 복제(Hot Key Replication)**:
   - 자주 읽히는 키를 여러 노드에 추가 복제
   - 읽기 요청을 복제본들에 분산
   - 캐시 레이어 추가 (Redis, Memcached)

2. **키 샤딩 재설계**:
   - 핫키에 랜덤 접미사 추가 (예: `hot_key_1`, `hot_key_2`, ...)
   - 읽기 시 랜덤하게 선택하여 부하 분산
   - 쓰기 시 모든 샤드에 업데이트 필요 (트레이드오프)

3. **가상 노드 재조정**:
   - 부하가 높은 물리 서버의 가상 노드 수를 줄임
   - 부하가 낮은 서버의 가상 노드 수를 늘림
   - 점진적으로 데이터 재분배

4. **애플리케이션 레벨 캐싱**:
   - 클라이언트 측 또는 프록시 레벨에서 핫키 캐싱
   - DB 요청 자체를 줄임

5. **읽기 전용 복제본 추가**:
   - 핫 파티션에 대해서만 읽기 전용 복제본 추가 생성
   - 쓰기는 원본에만, 읽기는 복제본들에 분산

6. **Circuit Breaker/Rate Limiting**:
   - 과도한 요청을 제한하여 시스템 보호
   - 공정한 자원 분배

**예방책**:
- 초기 설계 시 키 설계 가이드라인 수립
- 사용자 ID 같은 고르게 분산되는 값을 키에 포함
- 정기적인 부하 테스트로 핫 파티션 가능성 사전 파악
</details>

<details>
<summary>Q9. 분산 키-밸류 저장소에서 네트워크 파티션이 발생했을 때 구체적으로 어떻게 복구할 수 있을까요?</summary>

**감지 방법**:

1. **Gossip 프로토콜 기반 감지**:
   - 주기적인 heartbeat 실패로 노드 간 연결 끊김 감지
   - 일정 시간 이상 응답 없으면 파티션 의심

2. **Quorum 기반 감지**:
   - 과반수 노드와 통신 불가 시 파티션 상태로 판단

**파티션 중 동작 방식**:

1. **AP 시스템 (가용성 우선)**:
   - 양쪽 파티션 모두 읽기/쓰기 허용
   - 버전 벡터나 타임스탬프로 충돌 추적
   - 파티션 복구 후 충돌 해결 필요

2. **CP 시스템 (일관성 우선)**:
   - 과반수 노드가 없는 파티션은 읽기 전용 또는 서비스 중단
   - Raft, Paxos 같은 합의 프로토콜 사용
   - 과반수 파티션만 쓰기 허용

**복구 프로세스**:

1. **네트워크 복구 감지**:
   - Gossip 프로토콜로 양쪽 파티션의 노드가 서로를 재발견
   - 연결 상태가 안정화되었는지 일정 시간 관찰

2. **데이터 동기화 (Reconciliation)**:

   a. **Merkle Tree 기반 비교**:
   - 각 파티션의 데이터를 Merkle Tree로 요약
   - 루트 해시 비교로 차이 발견
   - 차이가 있는 서브트리만 비교하여 효율적으로 동기화

   b. **Read Repair**:
   - 읽기 요청 시 여러 복제본 비교
   - 불일치 발견 시 최신 버전으로 업데이트

   c. **Anti-Entropy Repair**:
   - 백그라운드에서 모든 데이터 주기적으로 비교
   - 불일치 자동 수정

3. **충돌 해결 (Conflict Resolution)**:

   a. **Last Write Wins (LWW)**:
   - 타임스탬프 기반으로 최신 쓰기 채택
   - 간단하지만 데이터 손실 가능성

   b. **벡터 시계 기반**:
   - 인과관계 파악하여 최신 버전 결정
   - 동시 쓰기는 모두 보존하고 클라이언트에 반환

   c. **애플리케이션 정의 로직**:
   - 비즈니스 로직에 맞게 충돌 해결
   - 예: 쇼핑카트는 합집합, 카운터는 합산

4. **Hinted Handoff 처리**:
   - 파티션 중 임시 저장된 힌트 데이터를 원래 노드로 전송
   - 힌트 큐 비워지면 정상 상태 복구

5. **일관성 검증**:
   - 동기화 완료 후 무결성 체크
   - 복제 계수(N) 확인
   - 필요 시 추가 복구 작업 수행

**모범 사례**:
- 멀티 리전 배포로 단일 네트워크 장애 영향 최소화
- 정기적인 Anti-Entropy 실행으로 작은 불일치도 조기 해결
- 모니터링 및 알림으로 빠른 대응
- 카오스 엔지니어링으로 파티션 복구 테스트

실제로는 완전 자동화된 복구보다는, 운영자의 판단이 필요한 경우가 많습니다.
</details>

<details>
<summary>Q10. 장애 감지 방법 중 hinted handoff 방식과 anti-entropy protocol 방식은 어떤 차이점을 갖고 있을까요? 또 각각 어떤 상황에 적합할까요?</summary>

**Hinted Handoff**:

**개념**:
- 대상 노드가 일시적으로 다운되었을 때, 해당 노드의 데이터를 다른 노드가 "힌트"로 임시 보관
- 원래 노드가 복구되면 힌트를 전달하여 동기화

**동작 방식**:
1. 쓰기 요청 시 복제 대상 노드 A가 다운 상태
2. 다음 순서의 노드 B가 "A를 위한 데이터"라는 힌트와 함께 데이터 저장
3. A가 복구되면 B가 힌트를 A에 전달
4. A가 데이터를 받으면 B는 힌트 삭제

**장점**:
- 빠른 복구: 노드가 돌아오자마자 즉시 최신 상태로 복구
- 쓰기 가용성 보장: 일부 노드 다운 시에도 쓰기 성공
- 네트워크 효율성: 변경된 데이터만 전송

**단점**:
- 일시적 장애에만 유효 (힌트 저장 공간 한계)
- 힌트를 저장한 노드도 다운되면 데이터 손실 가능
- 장기 장애 시 힌트가 쌓여 저장 공간 압박

---

**Anti-Entropy Protocol**:

**개념**:
- 백그라운드에서 주기적으로 모든 복제본을 비교하여 불일치 해결
- Merkle Tree를 사용해 효율적으로 차이 탐지

**동작 방식**:
1. 각 노드가 데이터의 Merkle Tree 유지
2. 주기적으로 (예: 매 시간) 다른 복제본과 루트 해시 비교
3. 차이 발견 시 서브트리를 재귀적으로 비교
4. 불일치하는 실제 키-값만 동기화

**장점**:
- 장기 장애에도 복구 가능
- 모든 종류의 불일치 해결 (버그, 디스크 손상 등)
- 확실한 일관성 보장
- 힌트 손실 같은 예외 상황도 커버

**단점**:
- 주기적 실행으로 실시간성 부족
- 네트워크와 CPU 오버헤드
- 대용량 데이터셋에서는 비교 비용 높음

---

**비교표**:

| 구분 | Hinted Handoff | Anti-Entropy Protocol |
|------|---------------|----------------------|
| **타이밍** | 즉각적 (복구 시) | 주기적 (예: 매 시간) |
| **대상** | 일시적 장애 | 모든 불일치 |
| **복구 속도** | 빠름 | 느림 |
| **완전성** | 제한적 | 완전함 |
| **오버헤드** | 낮음 | 높음 |
| **적용 범위** | 최근 변경 데이터 | 전체 데이터셋 |

**적합한 상황**:

**Hinted Handoff가 적합한 경우**:
- 네트워크 순간 단절, 재시작 같은 짧은 다운타임 (분~시간 단위)
- 쓰기 가용성이 매우 중요한 시스템
- 빠른 복구가 우선인 경우
- 예: 실시간 추천 시스템, 세션 저장소

**Anti-Entropy Protocol이 적합한 경우**:
- 장기 장애 복구 (시간~일 단위)
- 데이터 일관성이 매우 중요한 시스템
- 디스크 손상, 소프트웨어 버그 같은 예상치 못한 불일치 해결
- 예: 금융 거래 데이터, 사용자 계정 정보

**실무에서는 두 방식을 조합**:
- Hinted Handoff: 일차 방어선 (빠른 복구)
- Anti-Entropy: 이차 방어선 (완전한 일관성)
- 예: Cassandra, Riak 등은 두 방식 모두 구현

이렇게 계층화된 접근으로 빠른 복구와 장기 일관성을 동시에 달성할 수 있습니다.
</details>
