# 6장 키-값 저장소 설계 - 면접 꼬리 질문

### Q1. N=3, W=2, R=2로 설정했을 때 정말 강한 일관성이 보장되나요?

**예상 답변:**
- **수학적 보장:**
  - W+R = 4 > N = 3이므로 읽기와 쓰기가 최소 1개 노드에서 겹침
  - 읽기 시 최소 1개 노드는 최신 데이터를 가지고 있음 보장
  - 타임스탬프나 벡터 시계로 최신 버전 선택

- **실제 동작:**
  - 쓰기: 3개 노드에 요청 → 2개 성공 응답 대기
  - 읽기: 3개 노드에서 읽기 → 2개 응답 중 최신 버전 선택
  - 수학적으로 최소 1개는 최신 데이터 보유

- **예외 상황:**
  - 네트워크 지연으로 쓰기가 완료되지 않은 상태에서 읽기 발생
  - 타임스탬프 동기화 문제 (NTP drift)
  - 노드 장애로 W개 응답을 못 받으면 쓰기 실패

**설명:**
W=2, R=2 설정에서 쓰기 요청 시 S1, S2, S3 중 2개에 데이터를 성공적으로 쓰면 완료됩니다. 읽기 요청 시 3개 노드 중 2개에서 데이터를 읽는데, W+R>N이므로 수학적으로 최소 1개 노드는 최신 쓰기에 참여한 노드입니다. 따라서 2개 응답 중 타임스탬프나 벡터 시계를 비교해 최신 버전을 선택할 수 있습니다.

**꼬리 질문:**
- Q1-1. W=1, R=1로 설정하면 성능은 좋지만 어떤 문제가 생기나요?
  - 답변 힌트: 최신 데이터 보장 안 됨, 1개 노드만 응답하면 완료이므로 오래된 데이터 읽을 가능성

- Q1-2. W=3, R=1로 설정하면 어떤 장단점이 있나요?
  - 답변 힌트: 읽기 매우 빠름, 쓰기 느림, 가용성 낮음 (3개 모두 성공해야 함)

- Q1-3. 네트워크 파티션으로 2개 노드만 살아있을 때 W=2, R=2는 어떻게 동작하나요?
  - 답변 힌트: 여전히 동작 가능 (2개 노드로 W, R 만족), 하지만 1개 더 죽으면 불가능

---

### Q2. 벡터 시계의 단점은 무엇이고, 실무에서 어떻게 해결하나요?

**예상 답변:**
- **벡터 시계의 단점:**
  - 버전 리스트가 계속 증가 ([S1,1], [S2,1], [S3,1], [S4,1]...)
  - 쓰기 빈도가 높고 서버가 많으면 메타데이터 크기 증가
  - 클라이언트가 충돌 해결 로직을 구현해야 함

- **실무 해결책:**
  - **임계치 설정:** 벡터 시계가 N개를 초과하면 오래된 항목 제거
  - **Last Write Wins (LWW):** 타임스탬프 기반으로 간단히 해결 (일부 데이터 손실 가능)
  - **도메인별 병합 로직:** 쇼핑카트는 합치기, 카운터는 더하기
  - **Dotted Version Vector:** 효율적인 변형 알고리즘

- **트레이드오프:**
  - 정확성 vs 복잡성
  - DynamoDB는 LWW + 버전 번호
  - Cassandra는 타임스탬프 기반 LWW
  - Riak는 벡터 시계 + 클라이언트 병합

**설명:**
벡터 시계는 이론적으로 완벽하지만 실무에서는 복잡도가 문제입니다. 예를 들어 100개 서버에서 1000번 쓰기가 발생하면 벡터가 매우 길어집니다. Amazon은 임계치를 10~20개로 설정하고, 초과 시 가장 오래된 항목을 제거합니다. 이는 드물게 충돌 감지를 놓칠 수 있지만 실용적입니다. 많은 시스템이 단순한 타임스탬프 기반 LWW를 사용하며, 일부 데이터 손실을 감수합니다.

**꼬리 질문:**
- Q2-1. "쇼핑카트는 합치고, 카운터는 더하고, 텍스트는 충돌"이라는 차이는 왜 생기나요?
  - 답변 힌트: 데이터 타입의 의미론(semantics), CRDT 개념

- Q2-2. Last Write Wins에서 "나중"을 어떻게 판단하나요? 서버 시간이 다르면?
  - 답변 힌트: 물리적 타임스탬프 (NTP 동기화 필요), 논리적 타임스탬프 (Lamport clock)

---

### Q3. 가십 프로토콜로 장애를 감지하는데 얼마나 걸리나요?

**예상 답변:**
- **감지 시간 영향 요소:**
  - Gossip interval (주기): 보통 1초
  - 전파 속도: O(log N) 라운드에 전체 클러스터 전파
  - Failure threshold: 몇 초간 박동 없으면 장애로 판단 (보통 5~10초)

- **실제 예시:**
  - 10개 노드, 1초 gossip interval, 10초 threshold
  - S1 장애 발생 → 10초 후 인접 노드가 감지
  - 추가 2~3초에 전체 클러스터 인지 (log₂ 10 ≈ 3 라운드)
  - 총 12~13초

- **튜닝:**
  - 더 빠른 감지: interval 줄이기 (네트워크 부하 증가)
  - False positive 감소: threshold 늘리기 (감지 느려짐)

**설명:**
가십 프로토콜은 각 노드가 1초마다 무작위 노드에게 박동 정보를 전파합니다. S1이 죽으면 S1과 직접 통신하던 노드들이 10초간 박동이 없으면 장애로 의심합니다. 이 정보가 다른 노드로 가십을 통해 퍼져나가는데, 100개 노드라도 log₂ 100 ≈ 7 라운드면 전체에 전파됩니다. 따라서 총 17초 정도면 전체 클러스터가 인지합니다.

**꼬리 질문:**
- Q3-1. 네트워크가 느려서 일시적으로 응답이 늦는 것과 진짜 장애를 어떻게 구분하나요?
  - 답변 힌트: Phi Accrual Failure Detector, 확률 기반 판단

- Q3-2. 1000개 노드에서도 가십 프로토콜이 효율적인 이유는?
  - 답변 힌트: O(log N) 전파, 각 노드는 일정한 메시지만 전송

---

### Q4. 머클 트리는 왜 O(log N)으로 불일치를 찾을 수 있나요?

**예상 답변:**
- **트리 구조 특성:**
  - 이진 트리 높이 = log₂ N
  - 루트부터 비교해서 다른 서브트리만 탐색
  - 일치하는 서브트리는 건너뜀

- **실제 동작 (8개 데이터):**
  ```
  레벨 0: Root (1개 비교)
  레벨 1: 2개 해시 비교 → 왼쪽만 다름
  레벨 2: 왼쪽 2개만 비교 → 1개만 다름
  레벨 3: 리프 노드 1개 발견

  총 비교: 1+1+1+1 = 4회 (log₂ 8 + 1 = 4)
  전체 비교 시: 8회 필요
  ```

- **효율성:**
  - 100만 개 데이터: log₂ 1M ≈ 20회 비교
  - 전체 비교: 100만 회 필요
  - 네트워크 비용: 해시값(32바이트) vs 전체 데이터

**설명:**
머클 트리는 이진 트리로 각 부모 노드가 자식들의 해시입니다. 서버 A와 B가 동기화할 때 루트 해시를 먼저 비교합니다. 같으면 모든 데이터가 같으므로 종료. 다르면 왼쪽/오른쪽 자식 해시를 각각 비교하고, 다른 쪽만 계속 탐색합니다. 트리 높이가 log N이므로 최악의 경우에도 log N 깊이까지만 탐색하면 됩니다.

**꼬리 질문:**
- Q4-1. 머클 트리를 항상 최신으로 유지하려면 업데이트 비용은?
  - 답변 힌트: 데이터 변경 시 해당 리프부터 루트까지 O(log N)개 해시 재계산

- Q4-2. 여러 개 데이터가 불일치하면 어떻게 되나요?
  - 답변 힌트: 모든 불일치 데이터를 찾을 때까지 탐색, O(k log N), k는 불일치 개수

---

### Q5. CAP 이론에서 P(파티션 감내)가 필수라는데, CA 시스템은 정말 없나요?

**예상 답변:**
- **이론:**
  - 네트워크 분할은 불가피하므로 P는 필수
  - CA는 단일 서버 또는 같은 데이터센터 내 시스템에서만 가능
  - 분산 시스템은 반드시 CP 또는 AP 선택

- **CA라고 주장하는 시스템:**
  - 전통적 RDBMS (단일 서버)
  - 같은 랙의 서버들 (네트워크 분할 확률 극히 낮음)
  - 하지만 이것도 네트워크 장애 가능성은 있음

- **실무 관점:**
  - P는 "네트워크 분할 시에도 동작"이 아니라 "분할 허용"
  - CP 시스템: 분할 시 일관성 선택 (일부 요청 거부)
  - AP 시스템: 분할 시 가용성 선택 (최종 일관성)

**설명:**
CAP는 이론적 프레임워크입니다. 실제로 네트워크는 언제나 불안정하므로 분산 시스템은 파티션 발생을 가정해야 합니다. CA 시스템이라고 하는 것은 네트워크 분할 확률이 매우 낮은 환경(같은 데이터센터)을 의미하지만, 완전히 배제할 수는 없습니다. 은행 시스템도 CP이지 CA가 아닙니다.

**꼬리 질문:**
- Q5-1. 같은 데이터센터 내 서버들도 네트워크 분할이 발생하나요?
  - 답변 힌트: 스위치 장애, 랙 간 네트워크 단절, 케이블 문제

- Q5-2. CP와 AP 중 무엇을 선택할지 판단 기준은?
  - 답변 힌트: 도메인 특성 (금융=CP, SNS=AP), 사용자 경험, 비즈니스 요구사항

---

### Q6. 실무에서 키-값 저장소를 직접 구현하는 경우가 있나요? 아니면 DynamoDB 같은 걸 쓰나요?

**예상 답변:**

**1단계: 필요성 판단**
- **기존 솔루션 사용 (대부분의 경우):**
  - DynamoDB, Redis, Cassandra 등 검증된 시스템
  - 운영 부담 적음, 버그 적음, 문서화 잘됨
  - 스타트업이나 중소기업은 거의 항상 이 선택

- **직접 구현 (매우 드문 경우):**
  - 특수한 요구사항 (예: 초저지연 금융 거래)
  - 기존 솔루션으로 불가능한 규모 (예: Google 규모)
  - 제품 자체가 저장소 (예: Riak, ScyllaDB 같은 회사)

**2단계: 아키텍처 선택 (기존 솔루션 사용 시)**
- **단일 Redis (간단):**
  - DAU 10만 이하, QPS 1만 이하
  - 세션 저장소, 캐시
  - 복제본 1개 추가로 가용성 확보

- **Redis Cluster (중간):**
  - DAU 100만, QPS 10만
  - 안정 해시 기반 자동 샤딩
  - 마스터-슬레이브 복제

- **DynamoDB (대규모):**
  - DAU 1000만+, 글로벌 서비스
  - Auto Scaling, 다중 리전
  - On-demand 요금제

**3단계: 실무 고려사항**
- **비용:**
  - Redis 자체 운영 vs ElastiCache
  - DynamoDB On-Demand vs Provisioned

- **운영:**
  - 모니터링, 백업, 장애 대응
  - 팀의 전문성

- **성능:**
  - 지연 시간 요구사항 (P99 < 10ms?)
  - 처리량 (QPS)

**설명:**
실무에서 키-값 저장소를 밑바닥부터 구현하는 경우는 거의 없습니다. 대부분은:
- **소규모:** Redis 단일 인스턴스 + 복제본
- **중규모:** Redis Cluster (자동 샤딩, 안정 해시 내장)
- **대규모:** DynamoDB, Cassandra (완전 관리형)

직접 구현은 Google Bigtable, Facebook의 RocksDB처럼 기존 솔루션으로는 충족 못하는 극단적 요구사항이 있을 때만 고려합니다. 면접에서는 "구현 원리"를 묻는 것이지 "직접 만들라"는 것이 아닙니다.

**꼬리 질문:**
- Q6-1. DynamoDB vs Cassandra vs MongoDB, 어떻게 선택하나요?
  - 답변 힌트: DynamoDB=관리형+AWS, Cassandra=쓰기 중심+대규모, MongoDB=유연한 스키마+쿼리

- Q6-2. Redis는 키-값 저장소인데 왜 AP도 CP도 아닌가요?
  - 답변 힌트: 단일 노드는 CAP 적용 안 됨, Redis Cluster는 AP (최종 일관성)

- Q6-3. "우리만의 특수한 요구사항"이라는 주장, 어떻게 검증하나요?
  - 답변 힌트: 벤치마크 테스트, POC, 기존 솔루션 한계 정량적 측정

---

### Q7. 블룸 필터가 "거짓 양성은 있지만 거짓 음성은 없다"는 게 무슨 뜻인가요?

**예상 답변:**
- **거짓 양성 (False Positive):**
  - 실제로는 없는데 "있을 수 있다"고 판단
  - 블룸 필터: "데이터 있음" → 실제로는 없을 수 있음 (해시 충돌)
  - 결과: 불필요한 디스크 I/O 발생 (성능 저하)

- **거짓 음성 (False Negative):**
  - 실제로는 있는데 "없다"고 판단
  - 블룸 필터: **절대 발생 안 함**
  - "데이터 없음" → 100% 확실히 없음

- **왜 이런 특성인가:**
  - 비트 배열 + 해시 함수
  - 있으면 해당 비트 ON → 확실
  - 비트 ON이어도 다른 키 때문일 수 있음 → 불확실

- **실무 영향:**
  - 거짓 양성 비율 조절 가능 (비트 배열 크기, 해시 함수 개수)
  - 보통 1~2%로 설정
  - 98% 불필요한 디스크 I/O 제거

**설명:**
블룸 필터는 비트 배열입니다. 키를 삽입할 때 3개 해시 함수를 사용해 3개 비트를 1로 설정합니다. 검색 시 3개 비트를 확인하는데:
- 하나라도 0이면 → 확실히 없음 (거짓 음성 없음)
- 모두 1이면 → 있을 수 있음 (다른 키들이 우연히 같은 비트를 1로 만들었을 수 있음)

SSTable이 100개 있고 블룸 필터 없이 검색하면 100개 파일을 모두 열어봐야 하지만, 블룸 필터로 98개는 "확실히 없음"을 걸러내고 2개만 실제로 검색합니다.

**꼬리 질문:**
- Q7-1. 거짓 양성 비율을 0%로 만들 수 있나요?
  - 답변 힌트: 불가능 (해시 충돌), 비트 배열을 무한대로 크게 하면 근접 (비실용적)

- Q7-2. 블룸 필터에서 데이터를 삭제할 수 있나요?
  - 답변 힌트: 불가능 (비트를 0으로 하면 다른 키 영향), Counting Bloom Filter로 해결

---

### Q8. 정족수 합의 방식에서 네트워크 파티션이 발생하면 어떻게 되나요?

**예상 답변:**
- **시나리오 (N=5, W=3, R=3):**
  - 정상: S1, S2, S3, S4, S5
  - 파티션: [S1, S2] vs [S3, S4, S5]

- **결과:**
  - **왼쪽 파티션 (2개):**
    - W=3 불가능 (2개만 있음) → 쓰기 실패
    - R=3 불가능 → 읽기 실패

  - **오른쪽 파티션 (3개):**
    - W=3 가능 → 쓰기 성공
    - R=3 가능 → 읽기 성공

- **AP vs CP 특성:**
  - 이 시스템은 사실상 CP에 가까움
  - W+R>N이면 일관성 보장하지만 가용성 희생
  - W+R≤N이면 양쪽 모두 동작 가능 (AP), 일관성 희생

- **실무 대응:**
  - 느슨한 정족수: 5개 중 아무 3개에서만 쓰기 성공하면 OK
  - 힌트 핸드오프로 복구 대비

**설명:**
정족수 합의는 CAP의 C와 A를 조절하는 다이얼입니다. W=3, R=3는 강한 일관성을 선택한 것이므로 파티션 발생 시 가용성을 희생합니다. 반대로 W=1, R=1은 양쪽 파티션 모두 동작하지만 일관성을 잃습니다. 느슨한 정족수는 이 문제를 완화하는 방법으로, "원래 5개 중 3개"가 아니라 "살아있는 서버 중 아무 3개"를 인정합니다.

**꼬리 질문:**
- Q8-1. 느슨한 정족수를 사용하면 W+R>N의 일관성 보장은 어떻게 되나요?
  - 답변 힌트: 약화됨, 힌트 핸드오프로 복구할 때까지는 불일치 가능

- Q8-2. Split-brain 문제는 무엇이고 어떻게 방지하나요?
  - 답변 힌트: 양쪽 파티션이 각각 독립적으로 동작, Quorum으로 과반수만 쓰기 허용
