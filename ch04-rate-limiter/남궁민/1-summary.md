## Late Limiter를 사용하는 이유

1. DoS(Denial of Service) 공격에 의한 자원 고갈 방지
2. 비용 절감
3. 서버 과부하 방지

## 면접 질문 포인트

- Q1. 클라이언트 측 제한 장치인가, 서버 측 제한 장치인가?
  - 클라이언트 측에 두는 건 요청 위변조 때문에 안정적이지 못함
  - 서버에 함께 두는 것도 가능한 방법
  - 클라우드 마이크로서비스인 경우, 보통 API Gateway라는 미들웨어 활용
    - API Gateway는 처리율 제한 뿐만 아니라 SSL termination, 인증, IP whitelist 등의 기능들도 제공
    - 직접 만들기보다는 다양한 기능을 제공하는 상용 API Gateway를 쓰는 게 바람직하다
- Q2. API 호출 제어 기준은 무엇인가?
  - IP 주소인지, 사용자 ID인지, 디바이스를 식별할 것인지
- Q3. 스타트업 규모인가, 아니면 빅테크 규모인가? 분산 환경인가?
- Q4. 독립된 서비스인가, 아니면 애플리케이션 코드에 포함되는 것인가?
- Q5. 요청이 제한된 경우 사용자에게 알려야 하는가?

## 처리율 제한 알고리즘

### 토큰 버킷 알고리즘

- 간단하며 폭넓게 보편적으로 이용됨
- 아마존, 스트라이프가 사용

**동작 원리**

- 토큰 버킷은 지정된 용량을 가짐
- 버킷에는 용량이 가득 차기 전까지 주기적으로 일정량의 토큰이 채워짐
- 각 요청이 처리될 때마다 하나의 토큰 사용
- Late Limiter는 요청이 올 때마다 버킷에 토큰이 남아 있는지 검사

**특징**

- 2개의 인자값을 다뤄야 함
  - 버킷 크기: 최대 토큰 개수
  - refill rate: 주기 당 공급되는 토큰 개수
- 보통 엔드포인트마다 별도의 버킷으로 관리
  - 만약 IP 주소별 처리율 제한이라면 IP 주소마다 버킷을 하나씩 할당해야 함
  - 만약 시스템 전체 처리율 제한이라면 모든 요청이 하나의 버킷 공유

**장점**

- 구현이 쉬움
- 메모리 효율적
- 버스트 트래픽도 처리 가능

**단점**

- 2개의 인자값을 세밀하게 튜닝하는 것이 까다로움

### 누출 버킷 알고리즘

- 요청 처리율을 고정하는 방식
- 보통 FIFO 큐로 구현
- 쇼피파이가 사용

**동작 원리**

- 요청이 도착하면 큐 공간을 확인하고, 여유가 있으면 큐에 요청을 추가
- 큐가 가득 차 있는 경우 요청은 버려짐
- 지정된 시간마다 큐에서 요청을 꺼내서 처리

**특징**

- 2개의 인자값을 다룸
  - 버킷 크기: 큐 사이즈
  - outflow rate: 주기 당 요청 처리 개수, 보통 초 단위로 표현

**장점**

- 메모리 효율적
- 안정된 처리율이 필요한 경우 적합

**단점**

- 단기간 트래픽이 몰리면 오래된 요청이 쌓이고, 최신 요청이 버려질 수 있음
- 2개의 인자값을 세밀하게 튜닝하는 것이 까다로움

### 고정 윈도 카운터 알고리즘

**동작 원리**

- 타임라인을 고정 간격 윈도로 나누고, 각 윈도마다 정해진 카운터 설정
- 요청이 접수될 때마다 `counter++`
- 카운터 값이 임계치에 도달하면 새 요청은 버려짐

**장점**

- 메모리 효율적
- 동작을 이해하기 쉬움
- 트래픽 유입 시점이 특정적인 경우 적합

**단점**

- 윈도 경계 부근에 트래픽이 몰리면 양쪽 윈도에 걸쳐져서 제한량보다 2배의 트래픽이 처리될 수 있음

### 이동 윈도 로깅 알고리즘

- 고정 윈도 카운터 알고리즘의 경계 부근 트래픽 문제를 해결하는 방식

**동작 원리**

- 각 요청의 타임스탬프를 추적 관리하며, 보통 Redis Sorted Set에 보관
- 새 요청이 들어왔을 때 만료된 타임스탬프가 있다면 제거
- 새 요청의 타임스탬프는 처리 제한과 상관 없이 로그에 추가
- 요청의 처리는 윈도의 처리율 제한에 따라 전송

**장점**

- 윈도 구간 중 어느 순간에 트래픽이 들어와도 요청 처리 개수는 정교하게 제한됨

**단점**

- 거부된 요청의 타임스탬프도 저장해야 하므로 메모리 비효율적

### 이동 윈도 카운터 알고리즘

- 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 방식
- 세부 구현 방식이 저마다 다름

**장점**

- 단기간에 트래픽이 몰려도 대응 가능
- 메모리 효율적

**단점**

- 직전 시간대 요청량이 균등하게 분포되어 있다고 가정하기 때문에 허점이 발생할 수도 있지만 심각한 문제는 아님

## 개략적인 아키텍처

- Redis 기반 캐시 사용이 바람직하다
  - `INCR` 기반 카운터 활용
  - `EXPIRE` 기반 카운터 만료
- 클라이언트는 요청을 Late Limiter 미들웨어에 전송한다

## 상세 설계에서의 고려사항들

- 처리율 제한에 걸려 실패한 요청들은 나중에 재처리할 것인가?
- HTTP 응답 헤더 설정하기
  - `X-Ratelimit-Remaining` : 윈도 내 남은 요청 처리 개수
  - `X-Ratelimit-Limit` : 윈도 당 전송 가능한 요청 수
  - `X-Ratelimit-Retry-After` : (429 Too many request 응답 시) 요청 재전송이 가능할 때까지 남은 초
- 분산 환경에서 동시성 경합, 동기화 문제를 어떻게 해결할 것인가?
  - 동시성 경합: Redis의 Lua Script 혹은 Sorted Set 활용
  - 동기화: Rate Limiter가 여러 대여도 Redis는 한 대만 두고 중앙 처리하도록 설계
- 데이터센터를 활용한 에지 서버, 최종 일관성 모델과 함께 더욱 더 개선 가능
- 모니터링 관련
  - 채택한 처리율 제한 알고리즘이 얼마나 효율적으로 작동하는지 확인해야 함
  - 구간별 요청 처리 개수 등 적용한 처리율 제한 규칙이 효과적인지
  - 허용된 요청과 제한된 요청의 비율을 확인해주는 것이 좋다
- 추가 고려사항들
  - 경성으로 임계치를 절대 넘을 수 없게 할 것인지, 아니면 연성으로 임계치를 잠시 넘어가는 것을 허용할 것인지?
  - HTTP 계층에서의 제한 위주로 다뤘는데, OSI 7 계층 중 다른 계층에도 처리율 제한을 걸어야 할 것인지?
  - 클라이언트 측면에서, 처리율 제한에 잘 안 걸리도록 하는 방법들도 고려해봐야 한다
    - 클라이언트 측 캐시 활용으로 API 호출 횟수 절감
    - 메시지 전송 개수 절감
    - 클라이언트 측 예외 처리 코드 도입
    - 재시도가 필요할 경우 충분한 back-off 시간 설정해두기
