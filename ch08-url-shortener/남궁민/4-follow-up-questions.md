# 면접 꼬리 질문 (8장)

<details>
<summary>Q1. 원본 URL로 리다이렉션 응답 시 301 응답과 302 응답 중 어떤 것을 선택하실 것인가요? 그 이유는 뭔가요?</summary>

**301 Moved Permanently (영구 리다이렉션)**:

**특징**:
- 브라우저가 응답을 캐싱함
- 이후 동일한 단축 URL 요청 시 서버를 거치지 않고 바로 원본 URL로 이동
- 서버 부하 감소

**장점**:
- 서버 트래픽 절감
- 빠른 리다이렉션 (캐시 히트 시)
- 인프라 비용 절감

**단점**:
- 클릭 통계 수집 불가 (캐시된 요청은 서버에 도달하지 않음)
- A/B 테스팅 불가능
- URL 변경 시 브라우저 캐시 때문에 문제 발생 가능

**사용 사례**:
- 통계 수집이 불필요한 경우
- 트래픽이 매우 많아 서버 부하 절감이 중요한 경우
- 영구적으로 변경되지 않는 URL

---

**302 Found (임시 리다이렉션)**:

**특징**:
- 브라우저가 응답을 캐싱하지 않음
- 매번 서버를 거쳐 리다이렉션
- 모든 클릭이 서버에 기록됨

**장점**:
- 정확한 클릭 통계 수집 가능
- 사용자 행동 분석 가능 (IP, User-Agent, Referer 등)
- 실시간 모니터링 가능
- 원본 URL 변경 시 즉시 반영

**단점**:
- 높은 서버 부하
- 추가 네트워크 왕복 시간 (RTT)
- 인프라 비용 증가

**사용 사례**:
- 클릭 통계가 중요한 경우 (마케팅, 분석)
- URL을 동적으로 변경해야 하는 경우
- A/B 테스팅이 필요한 경우

---

**권장 사항**:

**대부분의 URL 단축 서비스는 302를 사용**합니다:
- Bitly, TinyURL 등 주요 서비스 모두 302 사용
- 클릭 통계가 URL 단축 서비스의 핵심 가치
- 광고 수익, 분석 데이터 제공 등 비즈니스 모델에 필수적

**예외적으로 301 사용**:
- 퍼머링크(Permalink) 제공 서비스
- 트래픽이 극도로 많고 통계가 불필요한 경우
- CDN과 조합하여 캐싱 최적화가 필요한 경우

**하이브리드 접근**:
- 기본적으로 302 사용
- 특정 URL에 대해서만 301 옵션 제공 (사용자 선택)
- 통계 수집 기간 종료 후 자동으로 301로 전환
</details>

<details>
<summary>Q2. Base64 대신 Base62를 사용하는 이유가 뭔가요?</summary>

**Base64의 문제점**:

1. **URL-unsafe 문자 포함**:
   - `+` (플러스): URL에서 공백으로 해석될 수 있음
   - `/` (슬래시): 경로 구분자와 충돌
   - `=` (등호): 패딩 문자, URL 파라미터와 혼동

2. **URL 인코딩 필요**:
   - 이들 문자를 사용하려면 퍼센트 인코딩 필요
   - 예: `+` → `%2B`, `/` → `%2F`
   - URL이 길어지고 복잡해짐

3. **가독성 문제**:
   - 특수문자로 인해 사용자가 입력하기 어려움
   - 음성으로 전달하기 어려움

**Base62의 장점**:

1. **URL-safe**:
   - 사용 문자: `[0-9a-zA-Z]` (62개)
   - 모든 문자가 URL에 안전하게 사용 가능
   - 추가 인코딩 불필요

2. **가독성**:
   - 알파벳과 숫자만 사용하여 직관적
   - 대소문자 구분으로 더 많은 조합 생성

3. **짧은 길이**:
   - Base62도 충분히 짧은 URL 생성 가능
   - 예: 62^7 = 약 3.5조 개 조합 (7자리)

**왜 Base62인가?**:
- Base64와 거의 동일한 효율성 (62 vs 64)
- URL-safe하여 추가 처리 불필요
- 단축 URL의 핵심 요구사항 충족
</details>

<details>
<summary>Q3. ID를 Base62로 변환하는 과정을 설명해주세요.</summary>

**Base62 문자 세트**:
```
0-9: 숫자 (10개)
a-z: 소문자 알파벳 (26개)
A-Z: 대문자 알파벳 (26개)
총 62개 문자
```

**매핑 테이블**:
```
0 → '0', 1 → '1', ..., 9 → '9'
10 → 'a', 11 → 'b', ..., 35 → 'z'
36 → 'A', 37 → 'B', ..., 61 → 'Z'
```

**변환 알고리즘 (10진수 → Base62)**:

1. **나눗셈 반복**:
   - ID를 62로 나눈 나머지를 구함
   - 나머지를 Base62 문자로 변환
   - 몫이 0이 될 때까지 반복

2. **결과 문자열 역순 배열**:
   - 나머지를 구한 순서의 역순이 최종 결과

**의사 코드**:

```
function toBase62(id):
    chars = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
    result = ""

    while id > 0:
        remainder = id % 62
        result = chars[remainder] + result
        id = id / 62

    return result if result else "0"
```

**역변환 (Base62 → 10진수)**:

```
function fromBase62(shortUrl):
    chars = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
    id = 0

    for each character in shortUrl:
        id = id * 62 + indexOf(character in chars)

    return id
```

**결론**: Base62 변환은 간단한 진법 변환이며, 62진수 나눗셈의 나머지를 문자로 매핑하는 과정입니다.
</details>

<details>
<summary>Q4. URL 클릭 통계를 어떻게 수집하고, 어떤 메트릭 위주로 수집할 것인가요?</summary>

**통계 수집 아키텍처**:

**1. 실시간 수집**:
```
사용자 클릭
  ↓
웹 서버 (로깅)
  ↓
메시지 큐 (Kafka, RabbitMQ)
  ↓
스트림 처리 (Kafka Streams, Flink)
  ↓
집계 저장 (Cassandra, ClickHouse, BigQuery)
```

**2. 배치 수집**:
```
로그 파일 (S3, HDFS)
  ↓
배치 처리 (Spark, Hadoop)
  ↓
데이터 웨어하우스 (Redshift, BigQuery)
  ↓
분석/시각화 (Tableau, Looker)
```

**기본 메트릭**:

1. **클릭 수**:
   - 총 클릭 수
   - 고유 클릭 수 (IP 기반)
   - 시간대별 클릭 수

2. **시간 정보**:
   - 클릭 타임스탬프
   - 시간대별/일별/주별/월별 집계
   - 피크 시간대 분석

3. **지리적 정보**:
   - 국가, 도시 (IP → GeoIP 매핑)
   - 언어 (Accept-Language 헤더)
   - 타임존

4. **디바이스 정보**:
   - User-Agent 파싱:
     - 브라우저 (Chrome, Safari, Firefox 등)
     - OS (Windows, macOS, iOS, Android 등)
     - 디바이스 타입 (Desktop, Mobile, Tablet)

5. **리퍼러 (Referrer)**:
   - 유입 경로 (어디서 클릭했는지)
   - 소셜 미디어, 검색 엔진, 직접 입력 등

**고급 메트릭**:

6. **사용자 세션**:
   - 세션 ID로 동일 사용자 추적
   - 클릭 패턴 분석
   - 재방문율

7. **변환율 (Conversion)**:
   - UTM 파라미터 추적
   - A/B 테스트 결과
   - 캠페인 효과 측정

8. **봇 감지**:
   - 비정상적으로 많은 클릭
   - User-Agent 기반 봇 필터링
   - CAPTCHA 우회 여부

**수집 방법**:

**1. 동기 수집 (단순)**:
```
클릭 발생 → DB에 즉시 기록 → 리다이렉션
```
- **문제**: DB 부하 증가, 응답 지연

**2. 비동기 수집 (권장)**:
```
클릭 발생 → 메시지 큐에 전송 → 즉시 리다이렉션
            ↓
     백그라운드 워커가 처리 → DB 저장
```
- **장점**: 빠른 응답, 확장 가능

**3. 로그 기반 수집**:
```
웹 서버 로그 (Nginx, Apache)
  ↓
로그 수집기 (Fluentd, Logstash)
  ↓
중앙 저장소 (Elasticsearch, S3)
  ↓
배치 분석
```
- **장점**: 서버 코드 변경 불필요, 안정적

**저장소 선택**:

| 저장소 | 용도 | 장점 |
|--------|------|------|
| Redis | 실시간 카운터 | 빠른 증감 연산 |
| Cassandra | 시계열 데이터 | 높은 쓰기 성능 |
| ClickHouse | 분석 쿼리 | OLAP에 최적화 |
| BigQuery | 데이터 웨어하우스 | 대규모 분석 |

**개인정보 보호**:
- IP 주소 해싱 또는 마스킹
- GDPR 준수: 사용자 동의 필요
- 보관 기간 설정 (예: 90일 후 삭제)

**최적화**:
- 배치 삽입 (Bulk Insert)로 DB 부하 감소
- 사전 집계로 실시간 대시보드 제공
- 파티셔닝 (날짜별, URL별)으로 쿼리 성능 향상

**결론**: 비동기 메시지 큐를 사용하여 클릭 이벤트를 수집하고, 기본 메트릭(클릭 수, 시간, 지리, 디바이스, 리퍼러)을 중심으로 분석하는 것이 효과적입니다.
</details>

<details>
<summary>Q5. 악의적인 URL을 어떻게 필터링할 것인가요?</summary>

**악의적인 URL 유형**:

1. **피싱(Phishing)**:
   - 금융 정보, 비밀번호 탈취 목적
   - 정상 사이트를 모방한 가짜 사이트

2. **멀웨어(Malware)**:
   - 바이러스, 랜섬웨어 배포
   - 드라이브 바이 다운로드

3. **스팸(Spam)**:
   - 광고 남용
   - 불법 상품 판매

4. **불법 콘텐츠**:
   - 저작권 침해
   - 성인 콘텐츠 (서비스 정책에 따라)

**필터링 전략**:

**1. 블랙리스트 기반**:

**외부 블랙리스트 API 활용**:
- **Google Safe Browsing API**:
  - Google이 관리하는 악성 URL 데이터베이스
  - 피싱, 멀웨어 사이트 실시간 탐지
  - 무료 (일일 API 호출 제한 있음)

- **VirusTotal API**:
  - 70개 이상의 백신 엔진 통합
  - URL/도메인 평판 조회

- **PhishTank**:
  - 커뮤니티 기반 피싱 사이트 데이터베이스

**구현**:
```
1. URL 단축 요청 수신
2. 원본 URL을 Safe Browsing API로 검사
3. 위험 판정 시 요청 거부
4. 안전하면 단축 URL 생성
```

**2. 휴리스틱 분석**:

**의심스러운 패턴 감지**:
- IP 주소 형식 URL (예: `http://192.168.1.1/...`)
- 비정상적으로 긴 URL (예: 2000자 이상)
- 의심스러운 TLD (`.tk`, `.ml` 등 무료 도메인)
- URL에 `login`, `verify`, `secure` 같은 피싱 키워드 포함
- 정상 도메인과 유사한 타이포스쿼팅 (예: `goog1e.com`)

**3. 도메인 평판 시스템**:

**평판 점수 계산**:
- 도메인 나이 (새 도메인은 의심)
- SSL/TLS 인증서 유무
- WHOIS 정보 (익명 등록은 의심)
- DNS 레코드 (MX, SPF 등)
- 과거 신고 이력

**4. 사용자 신고 시스템**:

**크라우드소싱**:
- 사용자가 악성 URL 신고 가능
- 신고 누적 시 자동 차단
- 신고자 평판 시스템 (허위 신고 방지)

**5. 컨텐츠 검사**:

**URL 페이지 크롤링**:
- 실제 페이지를 다운로드하여 분석
- HTML/JavaScript에서 악성 코드 패턴 탐지
- 리다이렉션 체인 추적 (다단계 리다이렉션 의심)

**주의**: 리소스 소모가 크므로 샘플링 또는 의심스러운 URL에만 적용

**6. 머신러닝 기반**:

**특징 추출**:
- URL 구조 (길이, 특수문자 비율, 서브도메인 수)
- 도메인 특징 (나이, 등록 정보)
- 컨텐츠 특징 (키워드, HTML 구조)

**모델 학습**:
- 레이블된 데이터셋 (악성/정상)
- Random Forest, XGBoost 등 분류 모델
- 주기적 재학습으로 새로운 위협 대응

**필터링 시점**:

**1. URL 생성 시 (사전 예방)**:
```
POST /api/shorten
  ↓
블랙리스트 검사
  ↓
휴리스틱 분석
  ↓
안전하면 생성, 위험하면 거부
```

**2. 주기적 재검사 (사후 탐지)**:
```
배치 작업 (매일 또는 매주)
  ↓
저장된 모든 URL 재검사
  ↓
새로 위험 판정된 URL 비활성화
  ↓
사용자에게 알림
```

**3. 클릭 시 실시간 검사**:
```
단축 URL 클릭
  ↓
캐시된 안전성 상태 확인
  ↓
의심스러우면 경고 페이지 표시
  ↓
사용자 선택 (계속 진행 / 취소)
```

**경고 페이지 표시**:
- "이 링크는 안전하지 않을 수 있습니다"
- 사용자 선택권 제공 (책임 전가)
- 클릭 통계에 경고 표시 기록

**오탐(False Positive) 대응**:
- 화이트리스트 관리 (신뢰할 수 있는 도메인)
- 사용자 이의 제기 시스템
- 수동 리뷰 프로세스

**성능 고려사항**:
- API 호출은 캐싱 (도메인별 결과 24시간 캐시)
- 비동기 검사로 URL 생성 속도 유지
- 배치 API 호출로 요청 수 절감

**법적 책임**:
- 이용 약관에 명시: "악성 URL 차단 노력하지만 100% 보장 불가"
- 신고 접수 후 즉시 조치
- 투명성 보고서 발행

**결론**: Google Safe Browsing API 같은 외부 블랙리스트와 휴리스틱 분석을 조합하고, 사용자 신고 시스템을 운영하여 다층 방어 체계를 구축하는 것이 효과적입니다.
</details>

<details>
<summary>Q6. SQL과 NoSQL 중 어떤 저장소에 URL을 저장할 것인가요?</summary>

**URL 단축 서비스 요구사항 분석**:

1. **읽기 집중적**: 읽기:쓰기 = 100:1 이상
2. **단순한 쿼리**: 주로 키-값 조회 (단축 URL → 원본 URL)
3. **높은 가용성**: 다운타임 최소화
4. **확장성**: 수억 건 이상 URL 저장
5. **낮은 지연**: 빠른 리다이렉션 필요

**권장 선택**: **NoSQL (DynamoDB, Cassandra) + SQL 조합**

**아키텍처**:

**1. 메인 저장소: NoSQL**
- **DynamoDB** 또는 **Cassandra**
- 단축 URL → 원본 URL 매핑 저장
- 빠른 읽기/쓰기, 수평 확장

**테이블 설계 (DynamoDB)**:
```
Table: url_mappings
Partition Key: short_url (예: "abc123")
Attributes:
  - original_url
  - user_id
  - created_at
  - expires_at
```

**2. 분석 저장소: SQL**
- **PostgreSQL** 또는 **MySQL**
- 사용자 정보, URL 메타데이터, 권한 관리
- 복잡한 분석 쿼리

**3. 통계 저장소: 전문 분석 DB**
- **ClickHouse**, **BigQuery**
- 클릭 로그 저장
- OLAP 쿼리 최적화

---

**하이브리드 접근의 장점**:

1. **NoSQL**: 빠른 리다이렉션 (메인 기능)
2. **SQL**: 비즈니스 로직, 사용자 관리
3. **분석 DB**: 통계 및 리포팅

**데이터 흐름**:
```
URL 생성 요청
  ↓
PostgreSQL (사용자 인증, 할당량 확인)
  ↓
DynamoDB (단축 URL 저장)
  ↓
응답 반환

---

리다이렉션 요청
  ↓
DynamoDB (단축 URL 조회)
  ↓
Redis (캐시)
  ↓
리다이렉션

---

클릭 통계
  ↓
Kafka (이벤트 스트림)
  ↓
ClickHouse (집계 저장)
```

**실무 예시**:
- **Bitly**: MongoDB (초기) → DynamoDB + PostgreSQL (현재)
- **TinyURL**: MySQL
- **Google URL Shortener (종료됨)**: Bigtable + BigQuery

**결론**: **NoSQL(DynamoDB/Cassandra)을 메인 저장소로 사용하고, SQL(PostgreSQL)을 보조 저장소로 활용**하는 하이브리드 아키텍처를 권장합니다. 이렇게 하면 빠른 성능과 복잡한 쿼리를 모두 지원할 수 있습니다.
</details>
