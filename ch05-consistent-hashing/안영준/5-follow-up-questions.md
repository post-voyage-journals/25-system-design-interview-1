# 5장 안정 해시 설계 - 면접 꼬리 질문

### Q1. 가상 노드의 개수는 어떻게 결정하나요?

**예상 답변:**
- **트레이드오프 고려:**
  - 가상 노드가 많을수록 → 더 균등한 분포, 하지만 메타데이터 관리 비용 증가
  - 적을수록 → 메모리 효율적, 하지만 불균등한 분포 가능성

- **실무적 기준:**
  - 서버 대수, 예상 트래픽, 메모리 제약 등을 고려
  - 100~200개는 경험적으로 균형이 좋은 수치
  - 통계적으로 표준편차가 충분히 작아지는 지점

- **동적 조정:**
  - 시스템 모니터링 결과에 따라 조정 가능
  - 부하 불균형 발생 시 가상 노드 수 증가 고려

**설명:**
가상 노드는 실제 물리 서버를 여러 개로 "복제"하여 해시 링에 배치하는 기법입니다. 예를 들어 서버 S1에 대해 150개의 가상 노드를 만든다면, hash("S1#0"), hash("S1#1"), ... hash("S1#149")처럼 각각 다른 위치에 배치됩니다. 가상 노드 개수가 많을수록 해시 링에서 더 골고루 분포되어 키가 균등하게 분배되지만, 각 가상 노드의 위치 정보를 저장해야 하므로 메모리 사용량이 증가합니다.

**꼬리 질문:**
- Q1-1. 가상 노드 개수를 서버마다 다르게 설정할 수 있나요? 어떤 경우에 그렇게 하나요?
  - 답변 힌트: 서버 성능이 다를 때 (고성능 서버에는 더 많은 가상 노드 할당)

- Q1-2. 가상 노드가 100개일 때와 1000개일 때 메모리 사용량 차이는 얼마나 되나요?
  - 답변 힌트: 각 가상 노드당 해시값(8바이트) + 서버 참조(8바이트) = 16바이트 정도, 서버 10대 기준 100개면 16KB, 1000개면 160KB

---

### Q2. 서버가 장애로 다운되었을 때 안정 해시는 어떻게 동작하나요?

**예상 답변:**
- **자동 재할당:**
  - 다운된 서버가 담당하던 키들이 해시 링의 다음 서버로 자동 이동
  - 클라이언트는 동일한 해시 계산을 통해 새로운 서버를 찾아감

- **장애 영향 범위:**
  - 다운된 서버가 담당하던 키만 영향받음
  - 다른 서버들의 키는 영향받지 않음

- **실무 고려사항:**
  - 캐시 시스템: 캐시 미스 발생, 원본에서 데이터 재로딩
  - 데이터 저장소: 복제(replication) 필요 (안정 해시 자체는 복제 기능 없음)

**설명:**
서버 S2가 다운되면, 해시 링에서 S2와 S2의 모든 가상 노드가 제거됩니다. 클라이언트가 키 K를 조회할 때, K의 해시값 위치에서 시계 방향으로 탐색하다가 이제 S2가 아닌 다음 서버(예: S3)를 만나게 됩니다. 캐시 시스템이라면 S3에 해당 키가 없으므로 캐시 미스가 발생하고 원본 DB에서 데이터를 가져옵니다. 영구 저장소라면 데이터 유실을 방지하기 위해 복제본이 필요합니다.

**꼬리 질문:**
- Q2-1. 복제본(replica)을 안정 해시와 함께 사용하려면 어떻게 설계해야 할까요?
  - 답변 힌트: 주 서버의 다음 N개 서버에 복제본 저장 (시계 방향으로 S1, S2, S3에 저장)

- Q2-2. 서버가 일시적으로 네트워크 장애로 응답하지 않는 경우와 완전히 죽은 경우를 어떻게 구분하나요?
  - 답변 힌트: Health check와 타임아웃 설정, 여러 번 재시도 후 판단

- Q2-3. 장애 서버가 복구되었을 때 어떻게 처리해야 하나요?
  - 답변 힌트: 점진적으로 가상 노드를 다시 추가, 데이터 동기화 필요

---

### Q3. 안정 해시를 사용하는 실제 시스템 사례를 아는 대로 말해보세요.

**예상 답변:**
- **Amazon DynamoDB:** 데이터 파티셔닝
- **Apache Cassandra:** 노드 간 데이터 분산
- **Memcached 클러스터:** 캐시 서버 분산
- **Akamai CDN:** 콘텐츠 배포
- **Discord:** 메시지 라우팅

각 시스템이 안정 해시를 선택한 이유:
- 수평적 확장성
- 노드 추가/제거 시 최소한의 데이터 이동
- 고가용성 유지

**설명:**
대표적으로 Amazon DynamoDB는 수백~수천 대의 서버에 데이터를 분산 저장할 때 안정 해시를 사용합니다. 트래픽 증가로 서버를 추가해도 전체 데이터를 재분배하지 않고 일부만 이동하면 되므로 서비스 중단 없이 확장 가능합니다. Cassandra도 클러스터에 노드를 추가/제거할 때 안정 해시 덕분에 인접한 노드 간에만 데이터 이동이 발생합니다.

**꼬리 질문:**
- Q3-1. Cassandra는 왜 특별히 안정 해시가 중요한가요?
  - 답변 힌트: P2P 구조로 모든 노드가 대등하며, 자주 노드가 추가/제거되는 환경

- Q3-2. CDN에서 안정 해시는 어떻게 활용되나요?
  - 답변 힌트: 콘텐츠를 엣지 서버에 분산 배치, 서버 추가/제거 시에도 대부분의 콘텐츠는 같은 위치 유지

---

### Q4. "핫스팟(Hot Spot)" 문제란 무엇이고, 안정 해시로 완전히 해결할 수 있나요?

**예상 답변:**
- **핫스팟 문제:**
  - 특정 키에 대한 요청이 집중되는 현상
  - 특정 서버에 부하가 과도하게 집중

- **안정 해시의 한계:**
  - 안정 해시는 키를 균등하게 "분배"하지만, "특정 키의 인기도"는 해결 못함
  - 예: 유명 연예인의 트윗 → 해당 키가 할당된 서버에 부하 집중

- **추가 해결책:**
  - 인기 키에 대한 별도 캐싱 레이어
  - 핫 키 감지 및 복제
  - 로드 밸런서 레벨에서의 처리
  - 데이터 샤딩 전략 재설계

**설명:**
안정 해시는 "키의 개수"를 균등하게 분배하지만 "키당 요청 횟수"까지는 고려하지 않습니다. 예를 들어 트위터에서 일반 사용자 1만 명의 트윗(각 10회 조회)과 유명인 1명의 트윗(100만 회 조회)이 있다면, 안정 해시는 키를 균등 분배하지만 유명인 트윗이 할당된 서버만 과부하가 걸립니다. 이는 안정 해시의 설계 범위를 벗어난 문제입니다.

**꼬리 질문:**
- Q4-1. 핫 키를 어떻게 감지할 수 있나요?
  - 답변 힌트: 각 서버가 키별 요청 횟수를 모니터링, 임계값 초과 시 알림

- Q4-2. 핫 키를 감지한 후 어떻게 처리하나요?
  - 답변 힌트: 로컬 캐시에 복제, CDN 활용, 읽기 전용 복제본 생성

- Q4-3. 핫 키를 미리 예측할 수 있다면 어떻게 설계하시겠습니까?
  - 답변 힌트: 핫 키는 안정 해시를 거치지 않고 별도의 전용 캐시 레이어로 라우팅

---

### Q5. 분산 캐시 시스템을 설계할 때 안정 해시를 어떻게 적용하시겠습니까?

**예상 답변:**

**1단계: 안정 해시 필요성 판단**
- **안정 해시를 사용해야 하는 경우:**
  - Auto Scaling 환경 (트래픽에 따라 캐시 서버 자동 증감)
  - 서버가 자주 추가/제거되는 환경 (월 1회 이상)
  - 24/7 무중단 운영이 필수인 서비스
  - DAU 100만 이상, 대규모 트래픽

- **일반 해시로 충분한 경우:**
  - 서버 대수가 고정적 (3~5대)
  - 야간 점검 시간에 재시작 가능
  - DAU 10만 이하, 캐시 워밍업이 5~10분 이내
  - 사내 도구나 점검 가능한 B2B 서비스

**2단계: 아키텍처 설계 (안정 해시 사용 시)**
- **클라이언트 측 구현:**
  - 클라이언트 라이브러리에 안정 해시 로직 구현
  - 서버 목록 관리 (설정 파일 or 서비스 디스커버리)
  - 가상 노드 100~200개 설정

- **장애 처리:**
  - Health check를 통한 서버 상태 감지
  - 장애 서버 자동 제거 및 복구 시 재추가

- **데이터 전략:**
  - 캐시 미스 시 원본 데이터베이스에서 로딩
  - 선택적으로 복제본 관리 (고가용성)

- **확장성:**
  - 서버 추가 시 점진적 트래픽 이동 (warm-up)
  - 모니터링 및 알림 시스템

**3단계: 비용-효과 분석**
- **도입 비용:** 개발 1~2주, 디버깅 복잡도 증가, 팀 학습 비용
- **얻는 효과:** 무중단 확장, 캐시 히트율 유지, Auto Scaling 가능
- **의사결정:** 현재 상황과 향후 3~6개월 계획 고려

**설명:**
분산 캐시 시스템 설계 시 가장 먼저 "안정 해시가 정말 필요한가?"를 판단해야 합니다. 예를 들어:

- **Case 1 (일반 해시 선택):** 사내 관리 도구, 서버 5대 고정, 주 1회 새벽 점검 가능
  → 일반 해시로 30분 만에 구현, 점검 시간에 재시작하면 충분

- **Case 2 (안정 해시 선택):** 전자상거래, DAU 200만, Auto Scaling 사용, 24/7 운영
  → Redis 클러스터 + 클라이언트 측 안정 해시 구현
  → 서버 목록은 Consul로 동적 관리
  → 트래픽 증가 시 서버 자동 추가, K/N 개 키만 재배치로 무중단 확장

안정 해시를 도입한다면, 클라이언트 라이브러리가 키를 해싱하고 해시 링에서 담당 서버를 찾아 직접 연결합니다. 서버 목록은 Zookeeper나 Consul 같은 서비스 디스커버리를 통해 동적으로 관리할 수 있습니다.

**꼬리 질문:**
- Q5-1. "우리 서비스는 안정 해시가 필요 없다"고 판단하는 구체적인 기준은?
  - 답변 힌트: 서버 증설 빈도(년 1~2회), 점검 시간 존재, DAU 10만 이하, 캐시 워밍업 시간 5분 이내, 다운타임 협의 가능

- Q5-2. 스타트업 CTO가 "우리도 대기업처럼 안정 해시 쓰자"고 하면 어떻게 설득하시겠습니까?
  - 답변 힌트: 현재 서버 증설 빈도 확인, 구현 비용(2주) vs 효과 비교, MVP 검증이 우선임을 강조, 일반 해시로 시작 후 필요시 전환 가능

- Q5-3. 클라이언트 측에서 안정 해시를 구현하는 것과 프록시 서버를 두는 것의 트레이드오프는?
  - 답변 힌트: 클라이언트 = 지연 시간 감소, 프록시 = 중앙 관리 용이, 클라이언트 업데이트 불필요

- Q5-4. 일반 해시로 시작했다가 나중에 안정 해시로 전환할 수 있나요? 마이그레이션 전략은?
  - 답변 힌트: 가능, 새 클라이언트는 안정 해시, 기존 클라이언트는 일반 해시로 이중 운영하다가 점진적 전환, 또는 점검 시간에 일괄 전환

- Q5-5. 서버 목록이 변경되었을 때 모든 클라이언트에게 어떻게 알리나요?
  - 답변 힌트: 서비스 디스커버리(Zookeeper, Consul), 주기적 polling, pub-sub 패턴

- Q5-6. 새 서버를 추가할 때 "warm-up"이 왜 필요한가요?
  - 답변 힌트: 빈 캐시 서버는 모든 요청이 캐시 미스가 되어 원본 DB에 부하, 점진적 트래픽 증가로 캐시 채움